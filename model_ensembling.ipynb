{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目标\n",
    "\n",
    "* 对于多种调参完成的模型进行模型融合。\n",
    "\n",
    "* 完成对于多种模型的融合，提交融合结果并打卡。\n",
    "\n",
    "## 内容介绍\n",
    "\n",
    "模型融合有如下的类型方式。\n",
    "\n",
    "1.  简单加权融合:\n",
    "    - 回归（分类概率）：算术平均融合（Arithmetic mean），几何平均融合（Geometric mean）；\n",
    "    - 分类：投票（Voting)\n",
    "    - 综合：排序融合(Rank averaging)，log融合\n",
    "\n",
    "\n",
    "2.  stacking/blending:\n",
    "    - 构建多层模型，并利用预测结果再拟合预测。\n",
    "\n",
    "\n",
    "4.  boosting/bagging（在xgboost，Adaboost,GBDT中已经用到）:\n",
    "    - 多树的提升方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1)  什么是 stacking\n",
    "简单来说 stacking 就是当用初始训练数据学习出若干个基学习器后，将这几个学习器的预测结果作为新的训练集，来学习一个新的学习器。\n",
    "![](http://jupter-oss.oss-cn-hangzhou.aliyuncs.com/public/files/image/2326541042/1584448793231_6TygjXwjNb.jpg)\n",
    ">将个体学习器结合在一起的时候使用的方法叫做结合策略。对于分类问题，我们可以使用投票法来选择输出最多的类。对于回归问题，我们可以将分类器输出的结果求平均值。上面说的投票法和平均法都是很有效的结合策略，还有一种结合策略是使用另外一个机器学习算法来将个体机器学习器的结果结合在一起，这个方法就是Stacking。在stacking方法中，我们把个体学习器叫做初级学习器，用于结合的学习器叫做次级学习器或元学习器（meta-learner），次级学习器用于训练的数据叫做次级训练集。次级训练集是在训练集上用初级学习器得到的。\n",
    "\n",
    "#### 2)  如何进行 stacking\n",
    "算法示意图如下：\n",
    "![](http://jupter-oss.oss-cn-hangzhou.aliyuncs.com/public/files/image/2326541042/1584448806789_1ElRtHaacw.jpg)\n",
    "* 过程1-3 是训练出来个体学习器，也就是初级学习器。\n",
    "* 过程5-9是 使用训练出来的个体学习器来得预测的结果，这个预测的结果当做次级学习器的训练集。\n",
    "* 过程11 是用初级学习器预测的结果训练出次级学习器，得到我们最后训练的模型。\n",
    "\n",
    "#### 3）Stacking的方法讲解\n",
    "首先，我们先从一种“不那么正确”但是容易懂的Stacking方法讲起。\n",
    "\n",
    "Stacking模型本质上是一种分层的结构，这里简单起见，只分析二级Stacking.假设我们有2个基模型 Model1_1、Model1_2 和 一个次级模型Model2\n",
    "\n",
    "**Step 1.** 基模型 Model1_1，对训练集train训练，然后用于预测 train 和 test 的标签列，分别是P1，T1\n",
    "\n",
    "Model1_1 模型训练:\n",
    "\n",
    "$$\n",
    "\\left(\\begin{array}{c}{\\vdots} \\\\ {X_{train}} \\\\ {\\vdots}\\end{array}\\right) \\overbrace{\\Longrightarrow}^{\\text {Model1_1 Train} }\\left(\\begin{array}{c}{\\vdots} \\\\ {Y}_{True} \\\\ {\\vdots}\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "训练后的模型 Model1_1 分别在 train 和 test 上预测，得到预测标签分别是P1，T1\n",
    "\n",
    "$$\n",
    "\\left(\\begin{array}{c}{\\vdots} \\\\ {X_{train}} \\\\ {\\vdots}\\end{array}\\right) \\overbrace{\\Longrightarrow}^{\\text {Model1_1 Predict} }\\left(\\begin{array}{c}{\\vdots} \\\\ {P}_{1} \\\\ {\\vdots}\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\left(\\begin{array}{c}{\\vdots} \\\\ {X_{test}} \\\\ {\\vdots}\\end{array}\\right) \\overbrace{\\Longrightarrow}^{\\text {Model1_1 Predict} }\\left(\\begin{array}{c}{\\vdots} \\\\ {T_{1}} \\\\ {\\vdots}\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "**Step 2.** 基模型 Model1_2 ，对训练集train训练，然后用于预测train和test的标签列，分别是P2，T2\n",
    "\n",
    "Model1_2 模型训练:\n",
    "\n",
    "$$\n",
    "\\left(\\begin{array}{c}{\\vdots} \\\\ {X_{train}} \\\\ {\\vdots}\\end{array}\\right) \\overbrace{\\Longrightarrow}^{\\text {Model1_2 Train} }\\left(\\begin{array}{c}{\\vdots} \\\\ {Y}_{True} \\\\ {\\vdots}\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "训练后的模型 Model1_2 分别在 train 和 test 上预测，得到预测标签分别是P2，T2\n",
    "\n",
    "$$\n",
    "\\left(\\begin{array}{c}{\\vdots} \\\\ {X_{train}} \\\\ {\\vdots}\\end{array}\\right) \\overbrace{\\Longrightarrow}^{\\text {Model1_2 Predict} }\\left(\\begin{array}{c}{\\vdots} \\\\ {P}_{2} \\\\ {\\vdots}\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\left(\\begin{array}{c}{\\vdots} \\\\ {X_{test}} \\\\ {\\vdots}\\end{array}\\right) \\overbrace{\\Longrightarrow}^{\\text {Model1_2 Predict} }\\left(\\begin{array}{c}{\\vdots} \\\\ {T_{2}} \\\\ {\\vdots}\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "**Step 3.** 分别把P1,P2以及T1,T2合并，得到一个新的训练集和测试集train2,test2.\n",
    "\n",
    "$$\n",
    "\\overbrace{\\left(\\begin{array}{c}{\\vdots} \\\\ {P_{1}} \\\\ {\\vdots}\\end{array} \\begin{array}{c}{\\vdots} \\\\ {P_{2}} \\\\ {\\vdots}\\end{array} \\right)}^{\\text {Train_2 }}  \n",
    "and \n",
    "\\overbrace{\\left(\\begin{array}{c}{\\vdots} \\\\ {T_{1}} \\\\ {\\vdots}\\end{array} \\begin{array}{c}{\\vdots} \\\\ {T_{2}} \\\\ {\\vdots}\\end{array} \\right)}^{\\text {Test_2 }}\n",
    "$$\n",
    "\n",
    "再用 次级模型 Model2 以真实训练集标签为标签训练,以train2为特征进行训练，预测test2,得到最终的测试集预测的标签列 $Y_{Pre}$。\n",
    "\n",
    "$$\n",
    "\\overbrace{\\left(\\begin{array}{c}{\\vdots} \\\\ {P_{1}} \\\\ {\\vdots}\\end{array} \\begin{array}{c}{\\vdots} \\\\ {P_{2}} \\\\ {\\vdots}\\end{array} \\right)}^{\\text {Train_2 }} \\overbrace{\\Longrightarrow}^{\\text {Model2 Train} }\\left(\\begin{array}{c}{\\vdots} \\\\ {Y}_{True} \\\\ {\\vdots}\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\overbrace{\\left(\\begin{array}{c}{\\vdots} \\\\ {T_{1}} \\\\ {\\vdots}\\end{array} \\begin{array}{c}{\\vdots} \\\\ {T_{2}} \\\\ {\\vdots}\\end{array} \\right)}^{\\text {Test_2 }} \\overbrace{\\Longrightarrow}^{\\text {Model1_2 Predict} }\\left(\\begin{array}{c}{\\vdots} \\\\ {Y}_{Pre} \\\\ {\\vdots}\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "Stacking本质上就是这么直接的思路，但是直接这样有时对于如果训练集和测试集分布不那么一致的情况下是有一点问题的，其问题在于用初始模型训练的标签再利用真实标签进行再训练，毫无疑问会导致一定的模型过拟合训练集，这样或许模型在测试集上的泛化能力或者说效果会有一定的下降，因此现在的问题变成了如何降低再训练的过拟合性，这里我们一般有两种方法。\n",
    "* 1. 次级模型尽量选择简单的线性模型\n",
    "* 2. 利用K折交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "import itertools\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "# from mlxtend.plotting import plot_learning_curves\n",
    "# from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.decomposition import PCA,FastICA,FactorAnalysis,SparsePCA\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入训练集和测试集\n",
    "train = pd.read_csv('../DATA/used_car_train_20200313/used_car_train_20200313.csv', sep=' ')\n",
    "test = pd.read_csv('../DATA/used_car_testA_20200313/used_car_testA_20200313.csv', sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SaleID', 'name', 'regDate', 'model', 'brand', 'bodyType', 'fuelType',\n",
      "       'gearbox', 'power', 'kilometer', 'regionCode', 'seller', 'offerType',\n",
      "       'creatDate', 'price', 'v_0', 'v_1', 'v_2', 'v_3', 'v_4', 'v_5', 'v_6',\n",
      "       'v_7', 'v_8', 'v_9', 'v_10', 'v_11', 'v_12', 'v_13', 'v_14'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "numerical_cols = train.select_dtypes(exclude = 'object').columns\n",
    "print(numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [col for col in numerical_cols if col not in ['SaleID','name','regDate','price']] # 变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model',\n",
       " 'brand',\n",
       " 'bodyType',\n",
       " 'fuelType',\n",
       " 'gearbox',\n",
       " 'power',\n",
       " 'kilometer',\n",
       " 'regionCode',\n",
       " 'seller',\n",
       " 'offerType',\n",
       " 'creatDate',\n",
       " 'v_0',\n",
       " 'v_1',\n",
       " 'v_2',\n",
       " 'v_3',\n",
       " 'v_4',\n",
       " 'v_5',\n",
       " 'v_6',\n",
       " 'v_7',\n",
       " 'v_8',\n",
       " 'v_9',\n",
       " 'v_10',\n",
       " 'v_11',\n",
       " 'v_12',\n",
       " 'v_13',\n",
       " 'v_14']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape: (150000, 26)\n",
      "X test shape: (50000, 26)\n"
     ]
    }
   ],
   "source": [
    "X_data = train[feature_cols]\n",
    "Y_data = train['price']\n",
    "\n",
    "X_test  = test[feature_cols]\n",
    "\n",
    "print('X train shape:',X_data.shape)\n",
    "print('X test shape:',X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sta of label:\n",
      "_min 11\n",
      "_max: 99999\n",
      "_mean 5923.327333333334\n",
      "_ptp 99988\n",
      "_std 7501.973469876438\n",
      "_var 56279605.94272992\n"
     ]
    }
   ],
   "source": [
    "def Sta_inf(data):\n",
    "    print('_min',np.min(data))\n",
    "    print('_max:',np.max(data))\n",
    "    print('_mean',np.mean(data))\n",
    "    print('_ptp',np.ptp(data))\n",
    "    print('_std',np.std(data))\n",
    "    print('_var',np.var(data))\n",
    "\n",
    "print('Sta of label:')\n",
    "Sta_inf(Y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = X_data.fillna(-1)\n",
    "X_test = X_test.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基学习器函数部分\n",
    "def build_model_lr(x_train,y_train):\n",
    "    reg_model = linear_model.LinearRegression()\n",
    "    reg_model.fit(x_train,y_train)\n",
    "    return reg_model\n",
    "\n",
    "def build_model_ridge(x_train,y_train):\n",
    "    reg_model = linear_model.Ridge(alpha=0.8)#alphas=range(1,100,5)\n",
    "    reg_model.fit(x_train,y_train)\n",
    "    return reg_model\n",
    "\n",
    "def build_model_lasso(x_train,y_train):\n",
    "    reg_model = linear_model.LassoCV()\n",
    "    reg_model.fit(x_train,y_train)\n",
    "    return reg_model\n",
    "\n",
    "def build_model_gbdt(x_train,y_train):\n",
    "    estimator =GradientBoostingRegressor(loss='ls',subsample= 0.85,max_depth= 5,n_estimators = 100)\n",
    "    param_grid = { \n",
    "            'learning_rate': [0.05,0.08,0.1,0.2],\n",
    "            }\n",
    "    gbdt = GridSearchCV(estimator, param_grid,cv=3)\n",
    "    gbdt.fit(x_train,y_train)\n",
    "    print(gbdt.best_params_)\n",
    "    # print(gbdt.best_estimator_ )\n",
    "    return gbdt\n",
    "\n",
    "def build_model_xgb(x_train,y_train):\n",
    "    model = xgb.XGBRegressor(n_estimators=120, learning_rate=0.08, gamma=0, subsample=0.8,\\\n",
    "        colsample_bytree=0.9, max_depth=5) #, objective ='reg:squarederror'\n",
    "    model.fit(x_train, y_train)\n",
    "    return model\n",
    "\n",
    "def build_model_lgb(x_train,y_train):\n",
    "    estimator = lgb.LGBMRegressor(num_leaves=63,n_estimators = 100)\n",
    "    param_grid = {\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "    }\n",
    "    gbm = GridSearchCV(estimator, param_grid)\n",
    "    gbm.fit(x_train, y_train)\n",
    "    return gbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. xgboost & 五折交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train mae: 600.0127885014529\n",
      "Val mae 691.9976473362078\n"
     ]
    }
   ],
   "source": [
    "## xgb\n",
    "xgr = xgb.XGBRegressor(n_estimators=120, learning_rate=0.1, subsample=0.8,\\\n",
    "        colsample_bytree=0.9, max_depth=7) # ,objective ='reg:squarederror'\n",
    "\n",
    "scores_train = []\n",
    "scores = []\n",
    "\n",
    "## 5折交叉验证方式\n",
    "sk=StratifiedKFold(n_splits=5,shuffle=True,random_state=0)\n",
    "for train_ind,val_ind in sk.split(X_data,Y_data):\n",
    "    \n",
    "    train_x=X_data.iloc[train_ind].values\n",
    "    train_y=Y_data.iloc[train_ind]\n",
    "    val_x=X_data.iloc[val_ind].values\n",
    "    val_y=Y_data.iloc[val_ind]\n",
    "    \n",
    "    xgr.fit(train_x,train_y)\n",
    "    pred_train_xgb=xgr.predict(train_x)\n",
    "    pred_xgb=xgr.predict(val_x)\n",
    "    \n",
    "    score_train = mean_absolute_error(train_y,pred_train_xgb)\n",
    "    scores_train.append(score_train)\n",
    "    score = mean_absolute_error(val_y,pred_xgb)\n",
    "    scores.append(score)\n",
    "\n",
    "print('Train mae:',np.mean(score_train))\n",
    "print('Val mae',np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 划分训练集和验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict LR...\n",
      "Predict Ridge...\n",
      "Predict Lasso...\n",
      "Predict GBDT...\n",
      "{'learning_rate': 0.2}\n",
      "predict XGB...\n",
      "predict lgb...\n"
     ]
    }
   ],
   "source": [
    "## Split data with val\n",
    "x_train,x_val,y_train,y_val = train_test_split(X_data,Y_data,test_size=0.3)\n",
    "\n",
    "## Train and Predict\n",
    "print('Predict LR...') # 训练线性模型\n",
    "model_lr = build_model_lr(x_train,y_train)\n",
    "val_lr = model_lr.predict(x_val)\n",
    "subA_lr = model_lr.predict(X_test)\n",
    "\n",
    "print('Predict Ridge...') # 训练岭回归模型\n",
    "model_ridge = build_model_ridge(x_train,y_train)\n",
    "val_ridge = model_ridge.predict(x_val)\n",
    "subA_ridge = model_ridge.predict(X_test)\n",
    "\n",
    "print('Predict Lasso...') # 训练lasso回归模型\n",
    "model_lasso = build_model_lasso(x_train,y_train)\n",
    "val_lasso = model_lasso.predict(x_val)\n",
    "subA_lasso = model_lasso.predict(X_test)\n",
    "\n",
    "print('Predict GBDT...') # 训练梯度助推树模型\n",
    "model_gbdt = build_model_gbdt(x_train,y_train)\n",
    "val_gbdt = model_gbdt.predict(x_val)\n",
    "subA_gbdt = model_gbdt.predict(X_test)\n",
    "\n",
    "print('predict XGB...') # 训练xgboost模型\n",
    "model_xgb = build_model_xgb(x_train,y_train)\n",
    "val_xgb = model_xgb.predict(x_val)\n",
    "subA_xgb = model_xgb.predict(X_test)\n",
    "\n",
    "print('predict lgb...') # 训练lgbm模型\n",
    "model_lgb = build_model_lgb(x_train,y_train)\n",
    "val_lgb = model_lgb.predict(x_val)\n",
    "subA_lgb = model_lgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sta inf of lgb:\n",
      "_min -290.70578615927286\n",
      "_max: 88843.18214796169\n",
      "_mean 5923.963348579981\n",
      "_ptp 89133.88793412097\n",
      "_std 7361.569664949637\n",
      "_var 54192707.93190671\n"
     ]
    }
   ],
   "source": [
    "# 查看对应模型结果信息\n",
    "print('Sta inf of lgb:')\n",
    "Sta_inf(subA_lgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 加权融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE of Weighted of val: 727.6078335730964\n",
      "Sta inf:\n",
      "_min -126.28208921691302\n",
      "_max: 87781.86118256024\n",
      "_mean 5926.475469161637\n",
      "_ptp 87908.14327177715\n",
      "_std 7342.7484125058445\n",
      "_var 53915954.2493571\n"
     ]
    }
   ],
   "source": [
    "def Weighted_method(test_pre1,test_pre2,test_pre3,w=[1/3,1/3,1/3]):\n",
    "    Weighted_result = w[0]*pd.Series(test_pre1)+w[1]*pd.Series(test_pre2)+w[2]*pd.Series(test_pre3)\n",
    "    return Weighted_result\n",
    "\n",
    "## Init the Weight\n",
    "w = [0.3,0.4,0.3]\n",
    "\n",
    "## 测试验证集准确度\n",
    "val_pre = Weighted_method(val_lgb,val_xgb,val_gbdt,w)\n",
    "MAE_Weighted = mean_absolute_error(y_val,val_pre)\n",
    "print('MAE of Weighted of val:',MAE_Weighted)\n",
    "\n",
    "## 预测数据部分\n",
    "subA = Weighted_method(subA_lgb,subA_xgb,subA_gbdt,w)\n",
    "print('Sta inf:')\n",
    "Sta_inf(subA)\n",
    "## 生成提交文件\n",
    "sub = pd.DataFrame()\n",
    "sub['SaleID'] = X_test.index\n",
    "sub['price'] = subA\n",
    "sub.to_csv('./sub_Weighted.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE of lr: 2604.399148900265\n"
     ]
    }
   ],
   "source": [
    "## 与简单的LR（线性回归）进行对比\n",
    "val_lr_pred = model_lr.predict(x_val)\n",
    "MAE_lr = mean_absolute_error(y_val,val_lr_pred)\n",
    "print('MAE of lr:',MAE_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* stacking融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Starking\n",
    "\n",
    "## 第一层\n",
    "train_lgb_pred = model_lgb.predict(x_train)\n",
    "train_xgb_pred = model_xgb.predict(x_train)\n",
    "train_gbdt_pred = model_gbdt.predict(x_train)\n",
    "\n",
    "Strak_X_train = pd.DataFrame()\n",
    "Strak_X_train['Method_1'] = train_lgb_pred\n",
    "Strak_X_train['Method_2'] = train_xgb_pred\n",
    "Strak_X_train['Method_3'] = train_gbdt_pred\n",
    "\n",
    "Strak_X_val = pd.DataFrame()\n",
    "Strak_X_val['Method_1'] = val_lgb\n",
    "Strak_X_val['Method_2'] = val_xgb\n",
    "Strak_X_val['Method_3'] = val_gbdt\n",
    "\n",
    "Strak_X_test = pd.DataFrame()\n",
    "Strak_X_test['Method_1'] = subA_lgb\n",
    "Strak_X_test['Method_2'] = subA_xgb\n",
    "Strak_X_test['Method_3'] = subA_gbdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method_1</th>\n",
       "      <th>Method_2</th>\n",
       "      <th>Method_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42914.115594</td>\n",
       "      <td>42021.500000</td>\n",
       "      <td>38987.492764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>256.828991</td>\n",
       "      <td>234.655716</td>\n",
       "      <td>173.310064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7045.212086</td>\n",
       "      <td>7358.294922</td>\n",
       "      <td>6897.966515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11559.495190</td>\n",
       "      <td>11721.629883</td>\n",
       "      <td>11535.499242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>572.137179</td>\n",
       "      <td>531.130005</td>\n",
       "      <td>573.708616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Method_1      Method_2      Method_3\n",
       "0  42914.115594  42021.500000  38987.492764\n",
       "1    256.828991    234.655716    173.310064\n",
       "2   7045.212086   7358.294922   6897.966515\n",
       "3  11559.495190  11721.629883  11535.499242\n",
       "4    572.137179    531.130005    573.708616"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Strak_X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE of Stacking-LR: 631.5752198437549\n",
      "MAE of Stacking-LR: 715.9727839065408\n",
      "Predict Stacking-LR...\n"
     ]
    }
   ],
   "source": [
    "## level2-method \n",
    "model_lr_Stacking = build_model_lr(Strak_X_train,y_train)\n",
    "## 训练集\n",
    "train_pre_Stacking = model_lr_Stacking.predict(Strak_X_train)\n",
    "print('MAE of Stacking-LR:',mean_absolute_error(y_train,train_pre_Stacking))\n",
    "\n",
    "## 验证集\n",
    "val_pre_Stacking = model_lr_Stacking.predict(Strak_X_val)\n",
    "print('MAE of Stacking-LR:',mean_absolute_error(y_val,val_pre_Stacking))\n",
    "\n",
    "## 预测集\n",
    "print('Predict Stacking-LR...')\n",
    "subA_Stacking = model_lr_Stacking.predict(Strak_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "subA_Stacking[subA_Stacking<10]=10  ## 去除过小的预测值\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub['SaleID'] = X_test.index\n",
    "sub['price'] = subA_Stacking\n",
    "sub.to_csv('./sub_Stacking.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sta inf:\n",
      "_min 10.0\n",
      "_max: 89491.56763852313\n",
      "_mean 5924.032525979502\n",
      "_ptp 89481.56763852313\n",
      "_std 7392.503284303548\n",
      "_var 54649104.80843875\n"
     ]
    }
   ],
   "source": [
    "print('Sta inf:')\n",
    "Sta_inf(subA_Stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
